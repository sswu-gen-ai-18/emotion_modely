import os
import glob
import whisper
from emotion_infer import predict_emotion  # ê°ì •ë¶„ì„ ëª¨ë“ˆ

def find_child(parent, keyword):
    """parent ì•ˆì—ì„œ ì´ë¦„ì— keywordê°€ ë“¤ì–´ê°„ í•˜ìœ„ í´ë”ë¥¼ ì°¾ì•„ì„œ ê²½ë¡œ ë°˜í™˜"""
    for name in os.listdir(parent):
        path = os.path.join(parent, name)
        if keyword in name and os.path.isdir(path):
            return path
    raise FileNotFoundError(f"'{keyword}' ë¥¼ í¬í•¨í•œ í´ë”ë¥¼ {parent} ì•ˆì—ì„œ ì°¾ì§€ ëª»í•¨")

DOWNLOADS = os.path.expanduser("~/Downloads")

# ë‹¨ê³„ë³„ íƒìƒ‰
step1 = find_child(DOWNLOADS, "022.")          # 022.ë¯¼ì›(ì½œì„¼í„°) ì§ˆì˜-ì‘ë‹µ ë°ì´í„°
step2 = find_child(step1, "01.")              # 01.ë°ì´í„°
step3 = find_child(step2, "Validation")       # 2.Validation...
step4 = find_child(step3, "ì›ì²œë°ì´í„°")       # ì›ì²œë°ì´í„°_220125_add  (ì—¬ê¸°ê¹Œì§€ ë‚´ë ¤ì˜´)
AUDIO_DIR = find_child(step4, "ì‡¼í•‘")         # ì‡¼í•‘ í´ë”

print("DOWNLOADS:", DOWNLOADS)
print("STEP1    :", step1)
print("STEP2    :", step2)
print("STEP3    :", step3)
print("STEP4    :", step4)
print("AUDIO_DIR:", AUDIO_DIR)
print("AUDIO_DIR exists?:", os.path.isdir(AUDIO_DIR))


# ðŸ”¹ 3) Whisper ëª¨ë¸ ë¡œë“œ
device = "mps"   # ì•ˆ ë˜ë©´ "cpu"
whisper_model = whisper.load_model("small", device=device)

def stt_whisper(audio_path: str) -> str:
    print(f"\n[STT] {os.path.basename(audio_path)}")
    result = whisper_model.transcribe(
        audio_path,
        language="ko",
        fp16=False,   # ðŸ”¥ ì´ ì¤„ ì¶”ê°€!
    )
    return result["text"]

def main():
    # ðŸ”¹ 4) os.walkë¡œ m4aë¥¼ ì „ë¶€ ì°¾ê¸° (ëŒ€ì†Œë¬¸ìž ë¬´ì‹œ)
    audio_files = []
    for root, dirs, files in os.walk(AUDIO_DIR):
        for f in files:
            if f.lower().endswith(".m4a"):
                audio_files.append(os.path.join(root, f))

    print("\nì°¾ì€ ìŒì„± íŒŒì¼ ê°œìˆ˜:", len(audio_files))
    print("ìƒ˜í”Œ 5ê°œ:")
    for p in audio_files[:5]:
        print(" -", p)

    if not audio_files:
        print("â— m4a íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í™•ìž¥ìžë‚˜ ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì¤˜.")
        return

    # ðŸ”¹ 5) ëª‡ ê°œë§Œ STT + ê°ì •ë¶„ì„
    for audio_path in audio_files[:5]:
        text = stt_whisper(audio_path)

        preview = text[:120].replace("\n", " ")
        print("[TEXT PREVIEW]:", preview, "..." if len(text) > 120 else "")

        label, score = predict_emotion(text)
        print("[EMOTION]:", label, f"(score={score:.4f})")

if __name__ == "__main__":
    main()
