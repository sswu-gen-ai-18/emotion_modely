# run_all_label_utter_emotion.py

import os
import glob
import json
import csv
from collections import defaultdict

from emotion_infer import predict_emotions_by_utterance


# ğŸ”¹ ë„¤ í™˜ê²½ì— ë§ê²Œ ê²½ë¡œë§Œ í™•ì¸/ìˆ˜ì •
TRAIN_LABEL_DIR = "/Users/ijiho/Downloads/022.ë¯¼ì›(ì½œì„¼í„°) ì§ˆì˜-ì‘ë‹µ ë°ì´í„°/01.ë°ì´í„°/1.Training/ë¼ë²¨ë§ë°ì´í„°_231222_add"
VAL_LABEL_DIR = "/Users/ijiho/Downloads/022.ë¯¼ì›(ì½œì„¼í„°) ì§ˆì˜-ì‘ë‹µ ë°ì´í„°/01.ë°ì´í„°/2.Validation/ë¼ë²¨ë§ë°ì´í„°_231222_add"


SPLITS = [
    ("train", TRAIN_LABEL_DIR),
    ("val",   VAL_LABEL_DIR),
]

OUTPUT_CSV = "/Users/ijiho/Desktop/callcenter_customer_emotions_all.csv"


def get_text_for_row(row: dict) -> str:
    """
    í•œ rowì—ì„œ ì‹¤ì œ ë°œí™” í…ìŠ¤íŠ¸ë¥¼ ë½‘ëŠ” í•¨ìˆ˜.
    í™”ì(ê³ ê°/ìƒë‹´ì‚¬)ì— ë”°ë¼ ì•Œë§ì€ í•„ë“œì—ì„œ êº¼ë‚¸ë‹¤.
    """
    speaker = row.get("í™”ì", "").strip()

    if speaker == "ê³ ê°":
        candidates = ["ê³ ê°ì§ˆë¬¸(ìš”ì²­)", "ê³ ê°ë°˜ë°•", "QA"]
    else:  # ìƒë‹´ì‚¬
        candidates = ["ìƒë‹´ì‚¬ë‹µë³€", "ìƒë‹´ì‚¬ë‹¤ë²•", "QA"]

    for k in candidates:
        v = (row.get(k) or "").strip()
        if v:
            return v
    return ""


def process_split(split_name: str, label_dir: str):
    """
    í•œ split(train ë˜ëŠ” val)ì˜ í´ë” ì•ˆì— ìˆëŠ”
    ëª¨ë“  .json íŒŒì¼ì„ ì²˜ë¦¬í•´ì„œ ê²°ê³¼ row ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´.
    """
    print(f"\n[INFO] Processing split={split_name}, dir={label_dir}")

    # í´ë” ì•ˆì˜ ëª¨ë“  json íŒŒì¼ ì°¾ê¸°
    json_paths = sorted(glob.glob(os.path.join(label_dir, "*.json")))
    print(f"  Found {len(json_paths)} json files")

    all_rows = []

    for json_path in json_paths:
        file_name = os.path.basename(json_path)
        print(f"  - {file_name}")

        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)  # ìµœìƒë‹¨ì´ ë¦¬ìŠ¤íŠ¸ë¼ê³  ê°€ì •

        # í†µí™”ë³„ë¡œ ë°œí™” ëª¨ìœ¼ê¸°
        dialogs = defaultdict(list)

        for row in data:
            conv_id = row.get("ëŒ€í™”ì‹ë³„ë²ˆí˜¸")
            if not conv_id:
                continue

            speaker = (row.get("í™”ì") or "").strip()
            text = get_text_for_row(row)
            # ë¬¸ì¥ë²ˆí˜¸ê°€ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ int ë³€í™˜
            try:
                turn = int(row.get("ë¬¸ì¥ë²ˆí˜¸", 0))
            except ValueError:
                turn = 0

            # ë„ë©”ì¸/ì¹´í…Œê³ ë¦¬ë„ ê°™ì´ ê¸°ë¡í•´ë‘ë©´ ë‚˜ì¤‘ì— ë¶„ì„ì— ìœ ë¦¬
            domain = row.get("ë„ë©”ì¸", "")
            category1 = row.get("ì¹´í…Œê³ ë¦¬1", "")

            dialogs[conv_id].append({
                "speaker": speaker,
                "text": text,
                "turn": turn,
                "domain": domain,
                "category1": category1,
            })

        # ê° í†µí™”ë³„ë¡œ ì •ë ¬ í›„ ê°ì • ë¶„ì„
        for conv_id, utterances in dialogs.items():
            # turn ìˆœìœ¼ë¡œ ì •ë ¬
            utterances.sort(key=lambda x: x["turn"])

            # ê³ ê° ë°œí™”ë§Œ ê°ì • ë¶„ì„ (ìƒë‹´ì‚¬ëŠ” ìë™ìœ¼ë¡œ ìŠ¤í‚µ)
            results = predict_emotions_by_utterance(
                utterances,
                speaker_key="speaker",
                text_key="text",
                customer_tag="ê³ ê°",   # í™”ì ê°’ì´ 'ê³ ê°'ì¸ ê²½ìš°ë§Œ ì‚¬ìš©
            )

            # ê²°ê³¼ ì •ë¦¬
            for r in results:
                # í•´ë‹¹ turnì˜ domain/category1 ì°¾ì•„ì˜¤ê¸°
                # (utterances ë¦¬ìŠ¤íŠ¸ì—ì„œ raw_turn_indexì— í•´ë‹¹í•˜ëŠ” ê²ƒ)
                meta = next(
                    (u for u in utterances if u["turn"] == r["raw_turn_index"]),
                    {"domain": "", "category1": ""}
                )

                all_rows.append({
                    "split": split_name,                       # train / val
                    "file": file_name,                         # ì–´ë–¤ jsonì—ì„œ ì™”ëŠ”ì§€
                    "call_id": conv_id,                        # ëŒ€í™”ì‹ë³„ë²ˆí˜¸
                    "domain": meta.get("domain", ""),
                    "category1": meta.get("category1", ""),
                    "customer_turn_index": r["customer_turn_index"],  # 1ë²ˆì§¸/2ë²ˆì§¸ ê³ ê° ë°œí™”
                    "raw_turn_index": r["raw_turn_index"],            # ì „ì²´ ë°œí™” ìˆœì„œ
                    "speaker": r["speaker"],                   # í•­ìƒ 'ê³ ê°'
                    "text": r["text"],
                    "emotion": r["emotion"],                   # anger / sad / fear
                    "score": r["score"],                       # í™•ë¥ 
                })

    return all_rows


def main():
    rows = []
    for split_name, label_dir in SPLITS:
        rows.extend(process_split(split_name, label_dir))

    # CSV ì €ì¥
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    with open(OUTPUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=[
                "split",
                "file",
                "call_id",
                "domain",
                "category1",
                "customer_turn_index",
                "raw_turn_index",
                "speaker",
                "text",
                "emotion",
                "score",
            ],
        )
        writer.writeheader()
        writer.writerows(rows)

    print(f"\n[DONE] Saved {len(rows)} rows to {OUTPUT_CSV}")


if __name__ == "__main__":
    main()
