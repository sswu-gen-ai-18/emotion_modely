import os
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# 1) Ïù¥ ÌååÏùºÏù¥ ÏûàÎäî ÏúÑÏπò Í∏∞Ï§ÄÏúºÎ°ú Î™®Îç∏ Ìè¥Îçî Í≤ΩÎ°ú
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "kobert_emotion_final")

print("MODEL_DIR:", MODEL_DIR)
print("FILES:", os.listdir(MODEL_DIR))

# 2) ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎäî HuggingFaceÏóêÏÑú ÏõêÎ≥∏ monologg/kobert ÏÇ¨Ïö©
tokenizer = AutoTokenizer.from_pretrained(
    "monologg/kobert",
    trust_remote_code=True,
)

# 3) Î™®Îç∏ÏùÄ ÎÑ§Í∞Ä fine-tune Ìïú Î°úÏª¨ Ìè¥ÎçîÏóêÏÑú Î°úÎìú
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR,
    local_files_only=True,
    trust_remote_code=True,
)
model.eval()

# 4) label Îß§Ìïë (configÏóê Ï†ÄÏû•Îèº ÏûàÏúºÎ©¥ Í±∞Í∏∞ÏÑú ÏùΩÍ≥†, ÏïÑÎãàÎ©¥ Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©)
if hasattr(model.config, "id2label") and model.config.id2label:
    id2label = {int(k): v for k, v in model.config.id2label.items()}
else:
    id2label = {0: "anger", 1: "sad", 2: "fear"}

print("ID2LABEL:", id2label)

def predict(text: str):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128,
    )
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        score, idx = torch.max(probs, dim=1)

    label = id2label[int(idx.item())]
    return label, float(score)

# üîπ Ïó¨Í∏∞ÏÑú emotion_inferÏùò "Î∞úÌôî Î¶¨Ïä§Ìä∏Ïö©" Ìï®Ïàò Í∞ÄÏ†∏Ïò§Í∏∞
from emotion_infer import predict_emotions_by_utterance


if __name__ == "__main__":
    # 1) Í∏∞Ï°¥Ï≤òÎüº Ìïú Î¨∏Ïû•Ïî© ÌÖåÏä§Ìä∏
    samples = [
        "Î∞∞ÏÜ°Ïù¥ ÎÑàÎ¨¥ Îä¶Ïñ¥Ïöî",
        "ÌôòÎ∂à Î∞õÍ≥† Ïã∂ÏùÄÎç∞Ïöî",
        "ÏßÑÏßú ÌôîÎÇò Ï£ΩÍ≤†Ïñ¥Ïöî",
        "ÏöîÏ¶ò ÎÑàÎ¨¥ Î∂àÏïàÌïòÍ≥† Í±±Ï†ïÎèºÏöî",
    ]
    print("=== Îã®Ïùº Î¨∏Ïû• ÌÖåÏä§Ìä∏ ===")
    for s in samples:
        print(s, "->", predict(s))

    # 2) Î∞úÌôî Î¶¨Ïä§Ìä∏(ÎåÄÌôî)Î°ú ÌÖåÏä§Ìä∏
    print("\n=== Î∞úÌôîÎ≥Ñ(Í≥†Í∞ù Î∞úÌôîÎßå) Í∞êÏ†ï ÌÖåÏä§Ìä∏ ===")
    conversation = [
        {"speaker": "customer", "text": "Ï†Ä Ïò§Îäò Í≤∞Ï†ú ÎÇ¥Ïó≠Ïù¥ Ïù¥ÏÉÅÌï¥ÏÑúÏöî.", "turn": 1},
        {"speaker": "agent",    "text": "Ïñ¥Îñ§ Ï†êÏù¥ Ïù¥ÏÉÅÌïòÏã†Í∞ÄÏöî?",       "turn": 2},
        {"speaker": "customer", "text": "Îëê Î≤à Í≤∞Ï†úÎêú Í≤É Í∞ôÏïÑÏöî.",       "turn": 3},
        {"speaker": "agent",    "text": "ÌôïÏù∏Ìï¥ Î≥¥Í≤†ÏäµÎãàÎã§.",           "turn": 4},
        {"speaker": "customer", "text": "Ïù¥Îü∞ ÏùºÏù¥ ÏûêÍæ∏ ÏÉùÍ∏∞Î©¥ ÎÑàÎ¨¥ ÌôîÎÇòÏöî.", "turn": 5},
    ]

    # ‚ö†Ô∏è customer_tagÎäî ÎÑ§ Îç∞Ïù¥ÌÑ∞Ïóê ÎßûÏ∂∞ÏÑú "customer" ÎòêÎäî "Í≥†Í∞ù"ÏúºÎ°ú ÎßûÏ∂∞Ï§òÏïº Ìï¥
    results = predict_emotions_by_utterance(
        conversation,
        speaker_key="speaker",
        text_key="text",
        customer_tag="customer",  # AI-Hub ÏõêÏ≤úÎç∞Ïù¥ÌÑ∞ÏóêÏÑú Í≥†Í∞ùÏù¥ Ïñ¥ÎñªÍ≤å ÌëúÍ∏∞Îèº ÏûàÎäîÏßÄÏóê ÎßûÏ∂îÍ∏∞
    )

    for r in results:
        print(
            f"{r['customer_turn_index']}Î≤àÏß∏ Í≥†Í∞ù Î∞úÌôî "
            f"(Ï†ÑÏ≤¥ turn {r['raw_turn_index']}): \"{r['text']}\""
            f" -> Í∞êÏ†ï: {r['emotion']} (score={r['score']:.3f})"
        )
